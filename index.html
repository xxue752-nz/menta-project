<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Menta: A Small Language Model for On-Device Mental Health Prediction</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="description" content="Menta: A small language model for multi-task mental health prediction and on-device deployment." />
  <style>
    /* ====== å…¨å±€åŸºç¡€æ ·å¼ ====== */
    :root {
      --bg: #f7f7fb;
      --card-bg: #ffffff;
      --accent: #3f6df6;
      --accent-soft: rgba(63, 109, 246, 0.08);
      --text-main: #111827;
      --text-sub: #4b5563;
      --border-soft: #e5e7eb;
      --badge-bg: #eef2ff;
      --tag-bg: #f3f4ff;
      --radius-lg: 18px;
      --shadow-soft: 0 18px 40px rgba(15, 23, 42, 0.08);
      --max-width: 1080px;
    }

    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
    }

    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "SF Pro Text",
        "Segoe UI", sans-serif;
      background: radial-gradient(circle at top left, #e0ebff 0, #f7f7fb 40%, #f7f7fb 100%);
      color: var(--text-main);
      line-height: 1.6;
    }

    a {
      color: var(--accent);
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    /* ====== å¸ƒå±€ ====== */
    .page {
      max-width: var(--max-width);
      margin: 0 auto;
      padding: 28px 16px 60px;
    }

    header {
      display: flex;
      flex-direction: column;
      gap: 20px;
      margin-bottom: 32px;
    }

    /* é¡¶éƒ¨å¯¼èˆª */
    .top-nav {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 8px;
    }

    .brand {
      font-weight: 700;
      font-size: 1rem;
      letter-spacing: 0.03em;
      text-transform: uppercase;
      color: #1f2933;
    }

    .nav-links {
      display: flex;
      gap: 14px;
      font-size: 0.9rem;
    }

    .nav-links a {
      padding: 6px 10px;
      border-radius: 999px;
      background: transparent;
      transition: background 0.15s;
      color: var(--text-sub);
    }

    .nav-links a:hover {
      background: rgba(148, 163, 184, 0.18);
      text-decoration: none;
    }

    /* Hero å¡ç‰‡ */
    .hero {
      background: var(--card-bg);
      border-radius: 26px;
      padding: 26px 24px 24px;
      box-shadow: var(--shadow-soft);
      border: 1px solid rgba(148, 163, 184, 0.25);
      position: relative;
      overflow: hidden;
    }

    .hero::before {
      content: "";
      position: absolute;
      inset: -60px;
      background: radial-gradient(circle at top right,
          rgba(63, 109, 246, 0.18),
          transparent 55%);
      opacity: 0.9;
      pointer-events: none;
    }

    .hero-inner {
      position: relative;
      display: grid;
      grid-template-columns: minmax(0, 3fr) minmax(0, 2.4fr);
      gap: 22px;
      align-items: center;
    }

    @media (max-width: 900px) {
      .hero-inner {
        grid-template-columns: minmax(0, 1fr);
      }
    }

    .tagline {
      display: inline-flex;
      align-items: center;
      gap: 8px;
      font-size: 0.8rem;
      padding: 4px 10px;
      border-radius: 999px;
      background: rgba(15, 23, 42, 0.06);
      color: var(--text-sub);
      margin-bottom: 10px;
    }

    .tagline span.dot {
      width: 8px;
      height: 8px;
      border-radius: 999px;
      background: #22c55e;
      box-shadow: 0 0 0 4px rgba(34, 197, 94, 0.25);
    }

    h1.title {
      font-size: 2.1rem;
      line-height: 1.1;
      margin-bottom: 10px;
      letter-spacing: -0.03em;
    }

    .subtitle {
      font-size: 0.98rem;
      color: var(--text-sub);
      max-width: 520px;
      margin-bottom: 16px;
    }

    /* æŒ‰é’®ç»„ */
    .btn-row {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      margin-bottom: 10px;
    }

    .btn {
      display: inline-flex;
      align-items: center;
      gap: 8px;
      padding: 8px 14px;
      border-radius: 999px;
      font-size: 0.9rem;
      border: 1px solid rgba(148, 163, 184, 0.6);
      background: rgba(15, 23, 42, 0.02);
      cursor: pointer;
      text-decoration: none;
      color: var(--text-main);
      backdrop-filter: blur(4px);
      transition: all 0.15s ease-out;
    }

    .btn-primary {
      background: linear-gradient(135deg, #3f6df6, #4f46e5);
      border-color: transparent;
      color: white;
      box-shadow: 0 10px 25px rgba(79, 70, 229, 0.35);
    }

    .btn:hover {
      transform: translateY(-1px);
      box-shadow: 0 12px 26px rgba(15, 23, 42, 0.12);
      text-decoration: none;
    }

    .btn span.icon {
      font-size: 1.1rem;
    }

    .hero-meta {
      font-size: 0.8rem;
      color: var(--text-sub);
    }

    /* å³è¾¹ä¿¡æ¯å—ï¼šå°å¡ç‰‡ */
    .hero-side {
      display: flex;
      flex-direction: column;
      gap: 10px;
    }

    .stat-card {
      background: rgba(15, 23, 42, 0.8);
      color: #e5e7eb;
      border-radius: 18px;
      padding: 15px 16px;
      font-size: 0.86rem;
      box-shadow: 0 14px 30px rgba(15, 23, 42, 0.55);
    }

    .stat-card h3 {
      font-size: 0.9rem;
      margin-bottom: 6px;
      color: #e5e7ff;
    }

    .stat-pill-row {
      display: flex;
      flex-wrap: wrap;
      gap: 6px;
      margin-top: 4px;
    }

    .pill {
      border-radius: 999px;
      padding: 3px 10px;
      font-size: 0.74rem;
      background: rgba(148, 163, 184, 0.18);
      border: 1px solid rgba(148, 163, 184, 0.45);
    }

    .small-label {
      font-size: 0.72rem;
      opacity: 0.9;
      text-transform: uppercase;
      letter-spacing: 0.08em;
    }

    /* ä½œè€…ä¿¡æ¯åŒºåŸŸ */
    .authors-block {
      margin-top: 18px;
      font-size: 0.88rem;
    }

    .authors-line {
      display: flex;
      flex-wrap: wrap;
      gap: 12px;
      margin-bottom: 4px;
    }

    .author-name sup {
      font-size: 0.6rem;
      margin-left: 2px;
    }

    .affiliations {
      font-size: 0.82rem;
      color: var(--text-sub);
    }

    .email-note {
      font-size: 0.8rem;
      color: var(--text-sub);
      margin-top: 4px;
    }

    /* ====== ä¸»ä½“å†…å®¹ ====== */
    main {
      margin-top: 32px;
      display: grid;
      grid-template-columns: minmax(0, 2.3fr) minmax(0, 1.4fr);
      gap: 22px;
    }

    @media (max-width: 900px) {
      main {
        grid-template-columns: minmax(0, 1fr);
      }
    }

    section {
      margin-bottom: 22px;
    }

    .section-card {
      background: var(--card-bg);
      border-radius: var(--radius-lg);
      padding: 18px 18px 16px;
      border: 1px solid var(--border-soft);
      box-shadow: 0 6px 18px rgba(15, 23, 42, 0.04);
    }

    .section-title {
      font-size: 1.05rem;
      font-weight: 600;
      margin-bottom: 6px;
      display: flex;
      align-items: center;
      justify-content: space-between;
      gap: 6px;
    }

    .section-title small {
      font-size: 0.75rem;
      font-weight: 500;
      color: var(--text-sub);
    }

    .section-card p {
      font-size: 0.9rem;
      color: var(--text-sub);
      margin-bottom: 7px;
    }

    .section-card ul {
      margin-left: 16px;
      margin-top: 6px;
      font-size: 0.9rem;
      color: var(--text-sub);
    }

    .section-card li {
      margin-bottom: 4px;
    }

    .badge-row {
      display: flex;
      flex-wrap: wrap;
      gap: 6px;
      margin-top: 4px;
      margin-bottom: 4px;
    }

    .badge {
      font-size: 0.72rem;
      padding: 3px 8px;
      border-radius: 999px;
      background: var(--badge-bg);
      color: #3730a3;
      border: 1px solid rgba(129, 140, 248, 0.4);
    }

    .list-inline {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      font-size: 0.86rem;
      color: var(--text-sub);
    }

    .list-inline span {
      padding: 3px 8px;
      background: var(--tag-bg);
      border-radius: 999px;
    }

    .code-block {
      font-family: "SF Mono", ui-monospace, Menlo, Monaco, Consolas, "Liberation Mono",
        "Courier New", monospace;
      font-size: 0.82rem;
      background: #020617;
      color: #e5e7eb;
      padding: 10px 12px;
      border-radius: 12px;
      overflow-x: auto;
      border: 1px solid rgba(30, 64, 175, 0.7);
    }

    .code-block code {
      white-space: pre;
    }

    /* å³ä¾§æ çš„å°æ¨¡å—æ ‡é¢˜ */
    .side-heading {
      font-size: 0.9rem;
      font-weight: 600;
      margin-bottom: 6px;
    }

    .dataset-table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82rem;
      margin-top: 4px;
    }

    .dataset-table th,
    .dataset-table td {
      border: 1px solid var(--border-soft);
      padding: 4px 6px;
      text-align: left;
    }

    .dataset-table th {
      background: #f8fafc;
      font-weight: 600;
    }

    .highlight {
      background: var(--accent-soft);
      border-radius: 8px;
      padding: 6px 8px;
      font-size: 0.85rem;
      margin-top: 6px;
    }

    footer {
      margin-top: 30px;
      padding-top: 18px;
      border-top: 1px solid var(--border-soft);
      font-size: 0.8rem;
      color: var(--text-sub);
      display: flex;
      flex-wrap: wrap;
      justify-content: space-between;
      gap: 10px;
    }

    html {
      scroll-behavior: smooth;
    }
  </style>
</head>
<body>
  <div class="page">
    <!-- ================= HEADER / HERO ================= -->
    <header>
      <div class="top-nav">
        <div class="brand">Menta</div>
        <nav class="nav-links">
          <a href="#overview">Overview</a>
          <a href="#model">Model</a>
          <a href="#datasets">Datasets</a>
          <a href="#results">Results</a>
          <a href="#deployment">On-Device</a>
          <a href="#bibtex">BibTeX</a>
        </nav>
      </div>

      <div class="hero">
        <div class="hero-inner">
          <!-- å·¦ä¾§ï¼šæ ‡é¢˜ + æŒ‰é’® + ä½œè€… -->
          <div>
            <div class="tagline">
              <span class="dot"></span>
              <span>Small Language Model Â· On-device Mental Health Prediction</span>
            </div>

            <h1 class="title">
              Menta: A Small Language Model<br />
              for On-Device Mental Health Prediction
            </h1>

            <p class="subtitle">
              A 4B-parameter small language model jointly trained on six social-media
              mental health tasks for stress, depression, and suicidality, optimized
              for real-time, privacy-preserving on-device deployment.
            </p>

            <div class="btn-row">
              <!-- TODO: æ›¿æ¢ä¸ºçœŸæ­£çš„è®ºæ–‡ PDF / camera-ready é“¾æ¥ -->
              <a class="btn btn-primary" href="#" target="_blank">
                <span class="icon">ğŸ“„</span>
                <span>Paper PDF</span>
              </a>

              <!-- TODO: æ›¿æ¢ä¸ºä½ çš„ GitHub ä»£ç ä»“åº“é“¾æ¥ -->
              <a class="btn" href="#" target="_blank">
                <span class="icon">ğŸ’»</span>
                <span>Code</span>
              </a>

              <!-- TODO: å¦‚æœ‰ Hugging Face / 4open / demo é“¾æ¥ï¼Œå¯ä»¥åœ¨è¿™é‡ŒåŠ  -->
              <a class="btn" href="#" target="_blank">
                <span class="icon">ğŸ“±</span>
                <span>iOS Demo / App</span>
              </a>

              <!-- TODO: å¦‚å¼€æ”¾æ¨¡å‹/æƒé‡ï¼Œå¯åœ¨æ­¤å¤„æ·»åŠ  -->
              <a class="btn" href="#" target="_blank">
                <span class="icon">ğŸ“¦</span>
                <span>Model &amp; Weights</span>
              </a>
            </div>

            <div class="hero-meta">
              <!-- å¯ä»¥å†™ä¼šè®®/æœŸåˆŠä¿¡æ¯ -->
              <!-- TODO: ä¿®æ”¹ä¸ºæœ€ç»ˆæ¥æ”¶çš„ venueï¼Œä¾‹å¦‚ UbiComp/IMWUT 2025 ç­‰ -->
              <span><strong>Manuscript</strong>, 2025</span>
            </div>

            <!-- ä½œè€…ä¿¡æ¯ -->
            <div class="authors-block">
              <div class="authors-line">
                <span class="author-name">Tianyi Zhang<sup>1</sup></span>
                <span class="author-name">Xiangyuan Xue<sup>2</sup></span>
                <span class="author-name">Lingyan Ruan<sup>1</sup></span>
                <span class="author-name">Shiya Fu<sup>1</sup></span>
                <span class="author-name">Feng Xia<sup>3</sup></span>
                <span class="author-name">Simon D&apos;Alfonso<sup>1</sup></span>
                <span class="author-name">Vassilis Kostakos<sup>1</sup></span>
                <span class="author-name">Ting Dang<sup>1</sup></span>
                <span class="author-name">Hong Jia<sup>2</sup></span>
              </div>
              <div class="affiliations">
                <sup>1</sup> The University of Melbourne, Australia Â·
                <sup>2</sup> The University of Auckland, New Zealand Â·
                <sup>3</sup> RMIT University, Australia
              </div>
              <div class="email-note">
                Contact:&nbsp;
                <a href="mailto:t.zhang59@student.unimelb.edu.au">t.zhang59@student.unimelb.edu.au</a>,
                <a href="mailto:xxue752@aucklanduni.ac.nz">xxue752@aucklanduni.ac.nz</a>,
                <a href="mailto:hong.jia@auckland.ac.nz">hong.jia@auckland.ac.nz</a>
              </div>
            </div>
          </div>

          <!-- å³ä¾§ï¼šç®€è¦æ¨¡å‹ / æŒ‡æ ‡å¡ç‰‡ -->
          <div class="hero-side">
            <div class="stat-card">
              <h3>Menta at a glance</h3>
              <div class="badge-row">
                <span class="pill">4B SLM (Qwen3 backbone)</span>
                <span class="pill">Multi-task LoRA</span>
                <span class="pill">Balanced accuracyâ€“aware loss</span>
              </div>
              <p style="margin-top: 8px;">
                Jointly trained on six Reddit-based mental health classification tasks
                (stress, depression, and suicidality) with a cross-dataset, class-balanced
                optimization strategy.
              </p>
            </div>

            <div class="stat-card" style="background:#020617;">
              <div class="small-label">On-device deployment</div>
              <p style="margin-top: 4px;">
                Demonstrated real-time inference on an iPhone 15 Pro Max using
                <code>llama.cpp</code> with 4-bit GGUF quantization, requiring only ~3&nbsp;GB RAM.
              </p>
              <div class="stat-pill-row">
                <span class="pill">TTFT &lt; 1s (typical)</span>
                <span class="pill">Multi-task screening</span>
                <span class="pill">Privacy-preserving</span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </header>

    <!-- ================= MAIN CONTENT ================= -->
    <main>
      <!-- ========= å·¦ä¾§ï¼šä¸»è¦è¯´æ˜ ========= -->
      <div>
        <!-- Overview -->
        <section id="overview" class="section-card">
          <div class="section-title">
            <span>1. Overview</span>
            <small>What is Menta?</small>
          </div>
          <p>
            Menta is a small language model for digital mental health prediction from
            social media text. It focuses on early detection of stress, depression,
            and suicidality while remaining lightweight enough to run entirely on
            consumer devices.
          </p>
          <p>
            Instead of relying on large server-side LLMs, Menta targets on-device
            screening to support privacy-preserving and scalable mental health tools.
          </p>
          <ul>
            <li>4B-parameter small language model with Qwen3 backbone.</li>
            <li>Six mental health classification tasks on Reddit social media posts.</li>
            <li>LoRA-based multi-task fine-tuning with balanced-accuracyâ€“aware loss.</li>
            <li>Demonstrated iOS deployment using <code>llama.cpp</code>.</li>
          </ul>
        </section>

        <!-- Model & Training -->
        <section id="model" class="section-card">
          <div class="section-title">
            <span>2. Model &amp; Training</span>
            <small>Architecture and optimization</small>
          </div>
          <p>
            Menta is built on top of Qwen3-4B and fine-tuned with parameter-efficient
            LoRA adapters for multi-task mental health prediction.
          </p>
          <div class="badge-row">
            <span class="badge">Qwen3-4B backbone</span>
            <span class="badge">LoRA (r = 16, Î± = 32)</span>
            <span class="badge">Multi-task sampling</span>
            <span class="badge">Balanced accuracy surrogate loss</span>
          </div>
          <p style="margin-top: 6px;">
            The training pipeline jointly optimizes six tasks using a weighted combination
            of class-weighted cross-entropy and a differentiable surrogate of balanced
            accuracy, encouraging fair performance across imbalanced datasets.
          </p>
          <ul>
            <li>LoRA applied to query &amp; value projections in attention layers.</li>
            <li>Only ~0.1% of parameters are trainable, reducing memory and compute.</li>
            <li>Task-level sampling weights mitigate dataset size imbalance.</li>
            <li>Class-level weights and BACC loss tackle label imbalance.</li>
          </ul>
        </section>

        <!-- Results -->
        <section id="results" class="section-card">
          <div class="section-title">
            <span>3. Results</span>
            <small>SLMs vs LLMs</small>
          </div>
          <p>
            Menta outperforms zero-shot and few-shot prompting on nine existing SLMs
            and achieves competitive or superior accuracy compared to 13B-parameter
            mental-healthâ€“tuned LLMs on depression and stress tasks.
          </p>
          <ul>
            <li>Average improvement of ~15% over the best non-fine-tuned SLM baselines across six tasks.</li>
            <li>Competitive with 13B Mental-Alpaca and Mental-FLAN-T5 for stress and depression prediction.</li>
            <li>Approximately 3.25Ã— smaller than 13B LLMs, enabling mobile-friendly deployment.</li>
          </ul>
          <p class="highlight">
            TODO: åœ¨è¿™é‡Œæ’å…¥ä½ çš„å…·ä½“è¡¨æ ¼/å›¾ï¼ˆä¾‹å¦‚ ACC / BACC æŸ±çŠ¶å›¾ã€radar å›¾çš„æˆªå›¾ï¼‰ï¼Œ
            å¯ä»¥å°†å›¾ç‰‡ä¸Šä¼ åˆ°ä»“åº“ä¸­ï¼Œç„¶åä½¿ç”¨
            <code>&lt;img src="images/results.png" alt="Results figure" /&gt;</code>ã€‚
          </p>
        </section>

        <!-- Case Study -->
        <section class="section-card">
          <div class="section-title">
            <span>4. Case Study</span>
            <small>Qualitative analysis</small>
          </div>
          <p>
            Beyond aggregate metrics, Menta produces more calibrated predictions and
            reasonings for nuanced mental health cases compared to non-fine-tuned SLMs.
          </p>
          <p>
            For example, when a user describes a physical symptom and seeks reassurance,
            Menta recognises it as minimal depressive severity, while baseline models
            overestimate distress as severe depression.
          </p>
          <p class="highlight">
            TODO: ä½ å¯ä»¥ä»è®ºæ–‡é‡Œçš„ case figure ä¸­æˆªä¸€å¼ å›¾ï¼Œæ”¾åœ¨è¿™é‡Œä½œä¸º qualitative caseï¼Œ
            å†é…åˆ 2â€“3 å¥è¯´æ˜ã€‚
          </p>
        </section>
      </div>

      <!-- ========= å³ä¾§ï¼šDatasets / Deployment / BibTeX ========= -->
      <div>
        <!-- Datasets -->
        <section id="datasets" class="section-card">
          <div class="section-title">
            <span>Datasets</span>
            <small>Reddit-based benchmarks</small>
          </div>
          <p>
            Menta is trained on four expert-annotated Reddit corpora, covering stress,
            depression severity, suicidal ideation, and suicide risk categories.
          </p>
          <table class="dataset-table">
            <thead>
              <tr>
                <th>Task</th>
                <th>Dataset</th>
                <th>Label type</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Task 1</td>
                <td>Dreaddit</td>
                <td>Stress vs. non-stress</td>
              </tr>
              <tr>
                <td>Task 2â€“3</td>
                <td>DepSeverity</td>
                <td>Binary depression &amp; 4-level severity</td>
              </tr>
              <tr>
                <td>Task 4</td>
                <td>SDCNL</td>
                <td>Suicidal ideation vs. non-ideation</td>
              </tr>
              <tr>
                <td>Task 5â€“6</td>
                <td>CSSRS-Suicide</td>
                <td>Binary risk &amp; 5-level categories</td>
              </tr>
            </tbody>
          </table>
          <p style="margin-top: 6px;">
            TODO: åœ¨è¿™é‡ŒåŠ ä¸Šæ¯ä¸ªæ•°æ®é›†çš„å®˜æ–¹é“¾æ¥ï¼ˆå¦‚æœå…è®¸å…¬å¼€ï¼‰ï¼Œä»¥åŠæ•°æ®ä½¿ç”¨å’Œä¼¦ç†è¯´æ˜ã€‚
          </p>
        </section>

        <!-- On-device deployment -->
        <section id="deployment" class="section-card">
          <div class="section-title">
            <span>On-Device Deployment</span>
            <small>iOS + llama.cpp</small>
          </div>
          <p>
            We deploy Menta on iOS via <code>llama.cpp</code> with 4-bit GGUF quantization,
            using Metal acceleration on an iPhone&nbsp;15 Pro Max.
          </p>
          <ul>
            <li>Backend: <code>llama.cpp</code>, GGUF v3, Q4_K_M quantization.</li>
            <li>Device: iPhone 15 Pro Max, A17 Pro, 8&nbsp;GB RAM.</li>
            <li>Context window: 4,096 tokens, with KV-cache management.</li>
            <li>Multi-threaded inference with up to 8 threads.</li>
          </ul>
          <p class="highlight">
            TODO: å¯ä»¥æ”¾ä¸€å¼  app ç•Œé¢æˆªå›¾ï¼ˆè¾“å…¥ Reddit æ–‡æœ¬ â†’ è¾“å‡ºå¤šä»»åŠ¡é¢„æµ‹ï¼‰ï¼Œå¹¶é™„ä¸€ä¸ª
            â€œHow to runâ€ çš„é“¾æ¥ï¼ŒæŒ‡å‘ GitHub é‡Œçš„ READMEã€‚
          </p>
        </section>

        <!-- BibTeX -->
        <section id="bibtex" class="section-card">
          <div class="section-title">
            <span>BibTeX</span>
            <small>Cite Menta</small>
          </div>
          <p>
            TODO: è¿™é‡Œæ”¾ä½ æœ€ç»ˆçš„æ­£å¼ BibTeXï¼ˆç­‰è®ºæ–‡æœ‰ DOI / arXiv ID / ä¼šè®®ä¿¡æ¯åå†æ›´æ–°ï¼‰ã€‚
          </p>
          <div class="code-block">
            <code>
@article{menta2025,
  title   = {Menta: A Small Language Model for On-Device Mental Health Prediction},
  author  = {Zhang, Tianyi and Xue, Xiangyuan and Ruan, Lingyan
             and Fu, Shiya and Xia, Feng and D'Alfonso, Simon
             and Kostakos, Vassilis and Dang, Ting and Jia, Hong},
  journal = {TODO: venue},
  year    = {2025},
  note    = {Preprint}
}
            </code>
          </div>
        </section>
      </div>
    </main>

    <!-- ================= FOOTER ================= -->
    <footer>
      <span>Â© 2025 Menta Authors.</span>
      <span>
        <!-- TODO: å¦‚æœæœ‰å¼€æºåè®®å¯ä»¥å†™ï¼Œä¾‹å¦‚ MIT / Apache-2.0 -->
        Code &amp; models released for research use only. Please refer to the
        repository for license details.
      </span>
    </footer>
  </div>
</body>
</html>
